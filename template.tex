\documentclass{article}


\title{Labwork 1: Gradient Descent}

\begin{document}

\maketitle

\setlength\parindent{0pt}

\section{Introduction}

Gradient descent's definition: Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. It trains machine learning models by minimizing errors between predicted and actual results.

Usage: Find the minimum value of mean square error

\section{Implementation}

first, i create two functions  for calculating the assigned function y = x*x and its derivative  y' = 2x.
Then i calculate the gradient descent based on the functions.
gradient descent contains 4 input parameters:
init-input: the first provided input 
lr: learning rate, set to try many of learning rate later
threshold: the threshold for the value of dx, that allow us to stop iteration when we reached expected value
n-iterations: set limitation for iteration, that doesnt allow too many iterations when finding the minimum value of error.


\section{Evaluation}

Test with $y = x^4$

Output of your program

\section{Conclusion}

In this labwork, we did this, that, and the result is this.

An interesting finding is that.....

\end{document}
